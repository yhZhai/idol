# [ðŸ’ƒ IDOL: Unified Dual-Modal Latent Diffusion for Human-Centric Joint Video-Depth Generation](https://yhzhai.github.io/idol/)

<a href='https://yhzhai.github.io/idol/'><img src='https://img.shields.io/badge/Project-Page-Green'></a> <a href='https://arxiv.org/abs/2407.10937'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>

[Yuanhao Zhai](https://www.yhzhai.com/)<sup>1</sup>, [Kevin Lin](https://sites.google.com/site/kevinlin311tw/)<sup>2</sup>, [Linjie Li](https://scholar.google.com/citations?hl=en&user=WR875gYAAAAJ)<sup>2</sup>, [Chung-Ching Lin](https://scholar.google.com/citations?hl=en&user=legkbM0AAAAJ)<sup>2</sup>, [Jianfeng Wang](http://jianfengwang.me)<sup>2</sup>, [Zhengyuan Yang](https://zyang-ur.github.io)<sup>2</sup>, [David Doermann](https://cse.buffalo.edu/~doermann/)<sup>1</sup>, [Junsong Yuan](https://cse.buffalo.edu/~jsyuan/)<sup>1</sup>, [Zicheng Liu](https://scholar.google.com/citations?hl=en&user=bkALdvsAAAAJ)<sup>3</sup>, [Lijuan Wang](https://scholar.google.com/citations?hl=en&user=cDcWXuIAAAAJ)<sup>2</sup>

<sup>1</sup>State University of New Yort at Buffalo  &nbsp; | &nbsp;  <sup>2</sup>Microsoft &nbsp;| &nbsp;  <sup>3</sup>Advanced Micro Devices

**European Conference on Computer Vision (ECCV) 2024**

&nbsp;

**TL;DR**: Our IDOL enables human-centric joint video-depth generation, which could be rendered into realistic 2.5 videos.

![](static/images/teaser.png)

**All code and checkpoints will be released soon!**